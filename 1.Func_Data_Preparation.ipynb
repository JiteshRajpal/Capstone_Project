{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da10ebb1-51f8-4135-9862-afdb55556b36",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de7747e-b1db-48fc-a58d-71a56dbfbe26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sannan Dabir\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)# To display all the columns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f69876-4bb3-4ff7-b4c2-7fac1ef1b908",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reading the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3c192c-2fb7-43cb-a40f-87545ca2b739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('spykar_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2952b7-8211-4811-9334-014b10d99d03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581176 entries, 0 to 581175\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Unnamed: 0             581176 non-null  int64  \n",
      " 1   placed_date            581176 non-null  object \n",
      " 2   store_id               581176 non-null  int64  \n",
      " 3   item_code              581176 non-null  object \n",
      " 4   item_id                581176 non-null  int64  \n",
      " 5   l1_category            581176 non-null  object \n",
      " 6   l0_category            554449 non-null  object \n",
      " 7   l2_category            554449 non-null  object \n",
      " 8   mrp                    581176 non-null  float64\n",
      " 9   disc_percent           581176 non-null  float64\n",
      " 10  season                 545619 non-null  object \n",
      " 11  qty                    581176 non-null  int64  \n",
      " 12  attributes             581176 non-null  object \n",
      " 13  item_colour            575331 non-null  object \n",
      " 14  item_pattern           462785 non-null  object \n",
      " 15  item_primary_color     581176 non-null  object \n",
      " 16  item_primary_material  535002 non-null  object \n",
      " 17  item_product_fit       434872 non-null  object \n",
      " 18  item_occasion          553541 non-null  object \n",
      " 19  item_product_details   450997 non-null  object \n",
      " 20  item_brand_name        581176 non-null  object \n",
      " 21  item_gender            581134 non-null  object \n",
      " 22  item_neck_type         219528 non-null  object \n",
      " 23  item_sleeve_length     219169 non-null  object \n",
      " 24  item_topwear_length    190022 non-null  object \n",
      " 25  item_age_group         7984 non-null    object \n",
      "dtypes: float64(2), int64(4), object(20)\n",
      "memory usage: 115.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9caaff-2ebf-45dc-ab18-45aa89e97c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff00149-e809-4e34-b847-d2ab11569695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_dataframe(input_df):\n",
    "    \"\"\"\n",
    "    Preprocesses the input DataFrame according to the specified operations.\n",
    "\n",
    "    Args:\n",
    "    - input_df (pd.DataFrame): The input DataFrame to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Convert 'placed_date' column to datetime\n",
    "    input_df['placed_date'] = pd.to_datetime(input_df['placed_date'])\n",
    "\n",
    "    # Drop the 'Unnamed: 0' column\n",
    "    input_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "    # Replace 'Men,Women' with 'Unisex' in the 'item_gender' column\n",
    "    input_df['item_gender'] = input_df['item_gender'].replace({'Men,Women': 'Unisex'})\n",
    "\n",
    "    # Replace specified values in the 'season' column\n",
    "    input_df['season'] = input_df['season'].replace({'CORE': 'Core', 'AllSeason': 'All Season', 'Winter 2022': 'Winter-2022', 'Winter - 2021': 'Winter-2021'})\n",
    "\n",
    "    # Replace specified values in the 'item_occasion' column\n",
    "    input_df['item_occasion'] = input_df['item_occasion'].replace({'Daily wear': 'Daily Wear', 'Dailywear': 'Daily Wear', 'CASUAL': 'Casual'})\n",
    "\n",
    "    # Remove rows where 'l0_category' is in the specified list\n",
    "    input_df = input_df[~((input_df['l0_category'] == 'Personal Care, Personal Care') | \n",
    "                          (input_df['l0_category'] == 'Accessories, Accessories') | \n",
    "                          (input_df['l0_category'] == 'Clothing, Clothing'))]\n",
    "\n",
    "    # Return the processed DataFrame\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5521384-3012-459b-98b5-9d33bfeb8ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming your original DataFrame is named 'original_data'\n",
    "data = preprocess_dataframe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea599b36-8d01-4ad8-b8d6-b1c0e6e9d53b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Cleaning the item colour column as it has large number of repeated and incorrectly labelled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec704f6-b95c-481b-b634-afbda2325d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_colors(input_df):\n",
    "    \"\"\"\n",
    "    Preprocesses color-related columns in the input DataFrame according to the specified operations.\n",
    "\n",
    "    Args:\n",
    "    - input_df (pd.DataFrame): The input DataFrame to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Function to replace 'item_colour' with 'item_primary_color' if 'item_colour' contains a number\n",
    "    def replace_color(row):\n",
    "        if pd.notna(row['item_colour']) and any(char.isdigit() for char in str(row['item_colour'])):\n",
    "            return row['item_primary_color']\n",
    "        else:\n",
    "            return row['item_colour']\n",
    "\n",
    "    # Apply the function to create a new column 'new_item_colour'\n",
    "    input_df['new_item_colour'] = input_df.apply(replace_color, axis=1)\n",
    "\n",
    "    # Drop the original 'item_colour' column and rename 'new_item_colour' to 'item_colour'\n",
    "    input_df = input_df.drop('item_colour', axis=1).rename(columns={'new_item_colour': 'item_colour'})\n",
    "\n",
    "    # Converting the color labels into title format\n",
    "    input_df['item_colour'] = input_df['item_colour'].str.title()\n",
    "\n",
    "    # Replacing '-' and '_' with space in 'item_colour' values\n",
    "    input_df['item_colour'] = input_df['item_colour'].str.replace('[-_]', ' ', regex=True)\n",
    "\n",
    "    # Replacing '/' with ' & ' in the 'updated_item_colour' column\n",
    "    input_df['item_colour'] = input_df['item_colour'].str.replace('/', ' & ')\n",
    "\n",
    "    # Replace 'Lt.' with 'Light'\n",
    "    input_df['item_colour'] = input_df['item_colour'].str.replace('Lt.', 'Light ')\n",
    "\n",
    "    # Replace 'Dk.' with 'Dark'\n",
    "    input_df['item_colour'] = input_df['item_colour'].str.replace('Dk.', 'Dark ')\n",
    "\n",
    "    # Replace 'Dk.' with 'Dark'\n",
    "    input_df['item_colour'] = input_df['item_colour'].str.replace('Dk ', 'Dark')\n",
    "\n",
    "    # Replace extra spaces with a single space\n",
    "    input_df['item_colour'] = input_df['item_colour'].str.replace(r'\\s+', ' ')\n",
    "\n",
    "    # Custom function to add 'Blue' in front of 'Navy' where there is no 'Navy Blue' and 'Blue' is not already present\n",
    "    def add_blue_to_navy(color):\n",
    "        if pd.notna(color) and 'Navy' in color and 'Navy Blue' not in color and 'Blue' not in color:\n",
    "            return color.replace('Navy', 'Navy Blue')\n",
    "        return color\n",
    "\n",
    "    # Apply the custom function to create a new column 'updated_item_colour'\n",
    "    input_df['item_colour'] = input_df['item_colour'].apply(add_blue_to_navy)\n",
    "\n",
    "    # Replacing the same pair of colors with a single value\n",
    "    input_df['item_colour'] = input_df['item_colour'].replace({'Pink & White': 'White & Pink',\n",
    "                                                   'Red & White': 'White & Red',\n",
    "                                                   'White & Orange': 'Orange & White',\n",
    "                                                   'Grey & White': 'White & Grey',\n",
    "                                                   'White & Green': 'Green & White',\n",
    "                                                   'White & Yellow': 'Yellow & White',\n",
    "                                                   'Grey & Blue': 'Blue & Grey',\n",
    "                                                   'Grey & Yellow': 'Yellow & Grey',\n",
    "                                                   'Blue & Green': 'Green & Blue',\n",
    "                                                   'Blue & Pink': 'Pink & Blue',\n",
    "                                                   'Mid_Blue': 'Mid Blue',\n",
    "                                                   'Blue & Brown': 'Brown & Blue',\n",
    "                                                   'Peach & White': 'White & Peach',\n",
    "                                                   'White & Khaki': 'Khaki & White',\n",
    "                                                   'Blue & White': 'White & Blue',\n",
    "                                                   'White & Navy': 'Navy & White',\n",
    "                                                   'Navy & Khaki': 'Khaki & Navy',\n",
    "                                                   'Blue & Brown': 'Brown & Blue',\n",
    "                                                   'Blue & Yellow': 'Yellow & Blue',\n",
    "                                                   'Blue & Red': 'Red & Blue',\n",
    "                                                   'Khaki & White': 'White & Khaki',\n",
    "                                                   'Orange & White': 'White & Orange',\n",
    "                                                   'White & Red': 'Red & White',\n",
    "                                                   'Black & Blue': 'Blue & Black',\n",
    "                                                   'White & Black': 'Black & White',\n",
    "                                                   'Red & Blue': 'Blue & Red',\n",
    "                                                   'Grey & Olive Green': 'Olive Green & Grey',\n",
    "                                                   'Green & Navy Blue': 'Navy Blue & Green',\n",
    "                                                   'Grey & Navy Blue': 'Navy Blue & Grey',\n",
    "                                                   'Navy Blue & Black & White': 'Black & White & Navy Blue',\n",
    "                                                   'Grey Melange & Black': 'Black & Grey Melange',\n",
    "                                                   'Grey & Melange': 'Melange & Grey',\n",
    "                                                   'Black & Grey Melange': 'Grey Melange & Black',\n",
    "                                                   'Navy Blue & Grey Melange': 'Grey Melange & Navy Blue',\n",
    "                                                   'Anthra Melange & Yellow': 'Yellow & Anthra Melange',\n",
    "                                                   'White & Grey Melange': 'Grey Melange & White',\n",
    "                                                   'White & Navy Blue': 'Navy Blue & White',\n",
    "                                                   'Wine & Navy Blue': 'Navy Blue & Wine',\n",
    "                                                   'Olive Green & White': 'White & Olive Green',\n",
    "                                                   'Grey & Maroon': 'Maroon & Grey',\n",
    "                                                   'Grey Melange & Navy Blue': 'Navy Blue & Grey Melange',\n",
    "                                                   'White & Navy Blue & Red': 'Navy Blue & Red & White',\n",
    "                                                   'Red & Navy Blue': 'Navy Blue & Red'\n",
    "                                                               })\n",
    "\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88dd03ad-77f1-4fbd-99cf-8d13622d4b44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = preprocess_colors(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb573d-c8fb-4dd2-83f4-fd2f04fd9601",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Checking the number of nan values in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e17749-7260-4e59-8733-789ac15ffa86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_fillna_conflict(data):\n",
    "    \"\"\"\n",
    "    Preprocesses missing values, fills NaN values with mode within each 'item_id' group,\n",
    "    and removes rows with conflicting values within specified columns.\n",
    "\n",
    "    Args:\n",
    "    - data (pd.DataFrame): The input DataFrame to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    def fillna_mode(series):\n",
    "        mode_values = series.mode()\n",
    "        if not mode_values.empty:\n",
    "            return series.fillna(mode_values.iloc[0])\n",
    "        else:\n",
    "            return series\n",
    "\n",
    "    # Apply the fillna_mode function to each group defined by 'item_id'\n",
    "    df_filled = data.groupby('item_id').transform(fillna_mode)\n",
    "\n",
    "    # If you have specific columns to apply this operation, you can use:\n",
    "    # df_filled = df.groupby('item_id')[your_columns].transform(fillna_mode)\n",
    "\n",
    "    # Replace the original DataFrame with the filled one\n",
    "    data.update(df_filled)\n",
    "\n",
    "    columns_to_check = ['l1_category', 'l0_category', 'l2_category', 'season', 'item_colour',\n",
    "                        'item_pattern', 'item_primary_color', 'item_primary_material',\n",
    "                        'item_product_fit', 'item_occasion', 'item_product_details',\n",
    "                        'item_gender', 'item_neck_type', 'item_sleeve_length', 'item_topwear_length']\n",
    "\n",
    "    # Group by 'item_id' and check the number of unique values in each specified column\n",
    "    unique_combinations = data.groupby('item_id')[columns_to_check].nunique()\n",
    "\n",
    "    # Identify item IDs with conflicting values in any of the specified columns\n",
    "    conflicting_ids = unique_combinations[unique_combinations > 1].dropna(how='all')\n",
    "\n",
    "    # Store conflicting item IDs in a list\n",
    "    conflicting_ids_list = list(conflicting_ids.index)\n",
    "\n",
    "    # Removing the conflicting item ids from the main data\n",
    "    data = data[~(data['item_id'].isin(conflicting_ids_list))]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b45b505-581c-45a3-8bc8-3128620a6acb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sannan Dabir\\AppData\\Local\\Temp\\ipykernel_28476\\1762651946.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return series.fillna(mode_values.iloc[0])\n"
     ]
    }
   ],
   "source": [
    "data = preprocess_fillna_conflict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1590bba-182c-4700-b333-d8a199b20187",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Creating a main dataframe with all the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f9df56-3995-4a8d-8fa9-a2116d1a5617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_merge_and_group(input_df):\n",
    "    \"\"\"\n",
    "    Preprocesses the input DataFrame by grouping and merging based on specified columns.\n",
    "\n",
    "    Args:\n",
    "    - input_df (pd.DataFrame): The input DataFrame to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Group by specified columns and sum the 'qty' column\n",
    "    grouped_df = input_df.groupby(['placed_date', 'store_id', 'item_id', 'mrp'])['qty'].sum().reset_index()\n",
    "\n",
    "    # Merge with selected columns from the original DataFrame\n",
    "    main_df = pd.merge(grouped_df,\n",
    "                       input_df[['item_id', 'item_code', 'l1_category', 'l0_category', 'l2_category',\n",
    "                                  'season', 'item_colour', 'item_pattern', 'item_primary_color',\n",
    "                                  'item_primary_material', 'item_product_fit', 'item_occasion',\n",
    "                                  'item_gender', 'item_neck_type', 'item_sleeve_length',\n",
    "                                  'item_topwear_length', 'item_brand_name', 'item_age_group']],\n",
    "                       on='item_id',\n",
    "                       how='left')\n",
    "\n",
    "    # Drop duplicates based on all columns\n",
    "    main_df = main_df.drop_duplicates()\n",
    "\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c4dec2-5655-4e72-9959-208cfa446f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'data' is your original DataFrame\n",
    "main_df = preprocess_merge_and_group(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206435c-efe2-42aa-8d39-413c2ab6ea4e",
   "metadata": {},
   "source": [
    "#### Adding new feature to find initial introduction days and days since introduction of a product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6dc53c1-b6e6-4cb6-9193-ef913e259263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_dates_and_mrp(input_df):\n",
    "    \"\"\"\n",
    "    Preprocesses the input DataFrame by calculating initial introduction date,\n",
    "    days since introduction, and initial MRP for each item.\n",
    "\n",
    "    Args:\n",
    "    - input_df (pd.DataFrame): The input DataFrame to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Find the minimum placed date per item\n",
    "    min_date_per_item = input_df.groupby('item_id')['placed_date'].min().reset_index()\n",
    "    min_date_per_item.columns = ['item_id', 'initial_introduction_date']\n",
    "\n",
    "    # Merge with the main DataFrame\n",
    "    main_df = pd.merge(input_df, min_date_per_item, on='item_id', how='left')\n",
    "\n",
    "    # Calculate days since introduction\n",
    "    main_df['days_since_introduction'] = (main_df['placed_date'] - main_df['initial_introduction_date']).dt.days\n",
    "\n",
    "    # Sort the DataFrame by 'item_id' and 'placed_date' in ascending order\n",
    "    main_df.sort_values(['item_id', 'placed_date'], inplace=True)\n",
    "\n",
    "    # Add a new column 'initial_mrp' capturing the first MRP for each item\n",
    "    main_df['initial_mrp'] = main_df.groupby('item_id')['mrp'].transform('first')\n",
    "\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2baadc01-f87f-48b1-b378-3e353079d673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_df = preprocess_dates_and_mrp(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82152332-0c35-4359-ab06-d1abfed92d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 567675 entries, 176810 to 559559\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   placed_date                567675 non-null  datetime64[ns]\n",
      " 1   store_id                   567675 non-null  int64         \n",
      " 2   item_id                    567675 non-null  int64         \n",
      " 3   mrp                        567675 non-null  float64       \n",
      " 4   qty                        567675 non-null  int64         \n",
      " 5   item_code                  567675 non-null  object        \n",
      " 6   l1_category                567675 non-null  object        \n",
      " 7   l0_category                566866 non-null  object        \n",
      " 8   l2_category                566866 non-null  object        \n",
      " 9   season                     533819 non-null  object        \n",
      " 10  item_colour                562314 non-null  object        \n",
      " 11  item_pattern               455599 non-null  object        \n",
      " 12  item_primary_color         567675 non-null  object        \n",
      " 13  item_primary_material      524138 non-null  object        \n",
      " 14  item_product_fit           428432 non-null  object        \n",
      " 15  item_occasion              541620 non-null  object        \n",
      " 16  item_gender                567633 non-null  object        \n",
      " 17  item_neck_type             216819 non-null  object        \n",
      " 18  item_sleeve_length         216474 non-null  object        \n",
      " 19  item_topwear_length        187643 non-null  object        \n",
      " 20  item_brand_name            567675 non-null  object        \n",
      " 21  item_age_group             7928 non-null    object        \n",
      " 22  initial_introduction_date  567675 non-null  datetime64[ns]\n",
      " 23  days_since_introduction    567675 non-null  int64         \n",
      " 24  initial_mrp                567675 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(2), int64(4), object(17)\n",
      "memory usage: 112.6+ MB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600780d4-dade-401b-a9d0-d5e85efc4ebb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exporting the main_df to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d503600-69f2-4d36-87a3-00d30441813b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_df.to_csv('Main_Working_Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
